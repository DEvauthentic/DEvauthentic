{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNogyZkndp1UyYEyNHRBpzK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DEvauthentic/DEvauthentic/blob/main/LANGCHAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbhJVXPE57-W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONSOLIDATION LANGCHAIN**"
      ],
      "metadata": {
        "id": "u_koG2P_6DcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain est un framework permettant de concenoir des applications basées sur les LLMs et les Agents IA (Workflow Complet)"
      ],
      "metadata": {
        "id": "3DCAV6VO6KyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les composants de LangChain\n",
        "\n",
        "\n",
        "*   PromptTemplate\n",
        "*   LLM\n",
        "\n",
        "\n",
        "*   Chain\n",
        "*   Agent\n",
        "\n",
        "\n",
        "*   Tools\n",
        "*   Mémoires\n",
        "\n",
        "\n",
        "*   Document Loaders\n",
        "*   Retriver\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yP1vM8Rp6uUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Prompt Engenering**"
      ],
      "metadata": {
        "id": "uL-KRlQ87Q0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'st la capacité à bien formuler une requete pour un LLM de sorte à obtenir une réponse clair, précis et controllée.\n",
        "Avec LangChain il est concu à partir du **PromptTemplate** qui permet de concevoir des prompts avec des variables dynamiques.\n",
        "Le prompt Enginering va au dela des prompts classiques mais une écriture controllée de bout en bout du prompt, un fake fine tunning est vite faite sur le LLM ce qui lui rend plus précis et spécial.\n",
        "\n",
        "**Les types de PromptTemplate avec LangChain**\n",
        "\n",
        "\n",
        "*   PromptTemplate\n",
        "*   ChatPromptTemplate\n",
        "\n",
        "\n",
        "*   FewShotPromptTemplate\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H9z27r6s7a2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.LLM**"
      ],
      "metadata": {
        "id": "4M1txI7I-5fu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les LLMs sont au coeur meme des applications basées sur LangChain, cela permet à l'application de résoudre des problèmes complexes, d'utiliser pleinement des outils que l'on lui donne afin de parvenir à resoudre un problème donné.\n",
        "\n",
        "**Rappel sur les LLMs**\n",
        "LLM pour Large Language Model sont des Models d'IA capable de prédire des suite de données en ayant une partie, on se rappel de cela lors du cours sur l'apprentissage Auto Suppervisé.\n",
        "Mais on n'oublie pas que cette ascension est du en majeur partie au transformers (Mécanisme d'attention) qui permet désormais au model de pouvoir se rappeler sur une information de son début à sa fin.\n",
        "Pour plus nous rappeler des transformers nous pouvons aussi nous réferer au cours sur les transformers dans Hugging Face.\n",
        "\n",
        "Bon bref on est la pour parler de **LangChain** et non de **Hugging Face**.\n",
        "Quelques exemples de LLMs :\n",
        "\n",
        "\n",
        "*   GPT\n",
        "*   LLAMA\n",
        "\n",
        "\n",
        "*   GEMINI\n",
        "*   QWEN AI\n",
        "\n",
        "\n",
        "*   GROK AI\n",
        "*   MISTRAL AI\n",
        "\n",
        "\n",
        "*   DEEPSEEK\n",
        "* ETC\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CMaAlNOW_AR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.CHAIN**"
      ],
      "metadata": {
        "id": "Gb1Nfq-3EFmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les chains sont au cours de l'automatisation, de l'enchainement des requetes que l'on envoie au agents AI que nous verrons encore ensemble dans la suite.\n",
        "Une CHAIN peut\n",
        "\n",
        "\n",
        "*   Prendre en paramètre le LLM et le Promt et ensuite fait appel à sa méthode run() pour lancer l'opératon, c'est la fonction basique de la CHAIN avec LangChain.\n",
        "*   Faire plusieurs traitements de manière synchrone ou asynchrone, l'on peut récuperer le Output d'un Agent pour en faire le Input d'un autre Agent dans plusieurs Use Case avec CHAIN de LangChain.\n",
        "\n",
        "Exemple de type de CHAIN\n",
        "\n",
        "\n",
        "* CHAIN\n",
        "* SimpleSequentialChain\n",
        "* SequentialChain\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s_S7jrG-EMF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.AGENT**"
      ],
      "metadata": {
        "id": "9gIYaf-KGTLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un AGENT est une entité autonome capable de prendre des decision bien réflechis seul dans le but de résoudre un problème donné.\n",
        "En LangChain et dans les automatisations de manière génerale,les Agents sont au coeur du jeux, on parle désormais de \"Agent Ai\" ou encore de l'IA Agentic.\n",
        "\n",
        "Un agent doit etre initialisé ou crée, peut avoir des outils à sa disposition, une mémoire et plein plus, nous verrons en profondeur les Outils et les mémoires qu'un agent peut utiliser dans le cas de LangChain.\n",
        "\n",
        "**Initiliser un Agent ▶**\n"
      ],
      "metadata": {
        "id": "DBCQs0GgGWwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.TOOL**\n",
        "\n",
        "Un tool comme son nom l'indique est simplement un outil qu'un agent peut s'en servir.\n",
        "Cet outil en general peut etre une fonction (fonction classique que nous avons déja dans la programmation).\n",
        "Une Api d'un service externe (Via MCP).\n",
        "MCP est un concept crutial en ses temps de l'IA et nous allons l'aborder dans un autres cas autre que dans les TOOLs.\n",
        "\n",
        "**Créer un Tool ▶**\n",
        "Exemple : Un outil permettant de faire des calculs classiques mathématique.\n",
        "\n",
        "def calculatrice(text: str) -> str:\n",
        "    return str(eval(text))\n",
        "\n",
        "\n",
        "tool = Tool(\n",
        "\n",
        "    name=\"Calculatrice\",\n",
        "\n",
        "    func=calculatrice,\n",
        "\n",
        "    description=\"Utilise cette fonction pour faire des calculs mathématiques\n",
        "\n",
        "    simples. Exemple : 2+3*5\"\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "On voit clairement qu'un outil à un nom, la fonction qui est ce que l'outil pourra faire, une description qui est ce qui va permettre au LLM de savoir ce que l'outil fait en fait de bien l'exploiter, et un exemple qui est optionel.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OPrkW8mOHVo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.MEMORY**"
      ],
      "metadata": {
        "id": "3m_b8rz_JERg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voila un composant assez crutial de LangChain qu'est la Mémoire, c'est ce qui permet l'agent de se rappeler du context, des discutions antérieures et de pouvir mieux mener les discutions futures.\n",
        "Cette mémoire peut etre sous différents types:\n",
        "\n",
        "\n",
        "*   Mémoire Courte Terme\n",
        "*   Mémoire Longue Terme\n",
        "*   Mémoire Moyen Terme\n",
        "\n",
        "Exemple de cas des mémoires et comment passer une mémoire à un agent ?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F54ga3nXJHpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***MINI PROJETS LANGCHAIN***"
      ],
      "metadata": {
        "id": "vomGGEJ1J5iZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Projet 1***"
      ],
      "metadata": {
        "id": "Tjj7xHfzJ_rg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construire un système Ai capable de conseiller une personne connaissant son emploie son age."
      ],
      "metadata": {
        "id": "XgrZZdHVKDs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Projet 2***"
      ],
      "metadata": {
        "id": "A3TYMyN-KRnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construire un Agent ai capable de ▶\n",
        "=) Calculer\n",
        "=) Donner des infos sur la Méteo"
      ],
      "metadata": {
        "id": "e58_55J2KWUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0F-azFuI6HnT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}