{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOojUdzhS6XGRX+HjyLC3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DEvauthentic/DEvauthentic/blob/main/SYSTEME_RAG_COMPLETE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGb7YY0N2ugj",
        "outputId": "dad6de80-0e7c-4fc5-cc2c-26750732d53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contextual-client in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from contextual-client) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from contextual-client) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->contextual-client) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->contextual-client) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->contextual-client) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->contextual-client) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->contextual-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->contextual-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->contextual-client) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# Installation de packages requis pour la construction du RAG\n",
        "! pip install contextual-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib tqdm requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCn431Vz3tmq",
        "outputId": "b24ee0e8-00b7-4fa5-9a3b-f38b2d19cbf8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importation des différents modules**"
      ],
      "metadata": {
        "id": "JSLahgfo31w6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict\n",
        "from IPython.display import display, JSON\n",
        "import pandas as pd\n",
        "from contextual import ContextualAI\n",
        "import ast"
      ],
      "metadata": {
        "id": "aDhCZSXb30Jc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "S'authentifier au près de Contextual AI pour avoir une clé d'API"
      ],
      "metadata": {
        "id": "n7-B6DST39ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajouter la clé api de context ai à la variable d'environnement"
      ],
      "metadata": {
        "id": "hLgppJpM5_6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"CONTEXTUAL_API_KEY=\" .env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fub_EJC637kk",
        "outputId": "90d5b761-8b35-4907-d10e-8108796ab43e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONTEXTUAL_API_KEY= .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Maintenant que l'environnement est initilisé avec la clé de l'api de context Ai, créons l'instance de ce dernier pret à etre utiliser**"
      ],
      "metadata": {
        "id": "cWExeUve6Vpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize with your API key\n",
        "client = ContextualAI(\n",
        "    api_key=\"key-p_eu-gDkx-8DqFYklHUvSyCY0ETZFfrbwN0RaABKDzazzLVvI\"\n",
        ")"
      ],
      "metadata": {
        "id": "1Q0sowdl6i8z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPsGjDMN6pEF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Créons de la base de donnée des documents de finance pour avec Context Ai\n"
      ],
      "metadata": {
        "id": "R_Y64ml0653H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore_name = 'Financial_Demo_RAG'\n",
        "\n",
        "# Vérifier si le datastore existe\n",
        "datastores = client.datastores.list()\n",
        "existing_datastore = next((ds for ds in datastores if ds.name == datastore_name), None)\n",
        "\n",
        "if existing_datastore:\n",
        "    datastore_id = existing_datastore.id\n",
        "    print(f\"La base de connaissance existe déja et sera utilisée avec l'ID: {datastore_id}\")\n",
        "else:\n",
        "    result = client.datastores.create(name=datastore_name)\n",
        "    datastore_id = result.id\n",
        "    print(f\"Creation de nouvelle base de connaissance avec l'ID: {datastore_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97X0XByw8Wd7",
        "outputId": "7626b1f0-e7d7-454b-e58e-1b5efe1f5898"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La base de connaissance existe déja et sera utilisée avec l'ID: 60c3ed0f-8499-4b95-b59f-ce97bf4eaa31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passons à l'étape de la création des chunks, les chunks sont les portions des documents qui seront ensuite transformés en embeddings qui à leur tour seront stockés dans une base de donnée Vectorielle, ici la base de donnée de Context Ai**"
      ],
      "metadata": {
        "id": "ormYcq9RDX-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Les formats de fichiers supportés :**\n",
        "\n",
        "1.   PDF\n",
        "\n",
        "2.  HTML\n",
        "3.  DOC/DOCX\n",
        "\n",
        "\n",
        "4.  PPT/PPTX\n",
        "\n"
      ],
      "metadata": {
        "id": "QimV9h0EDzaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# Créer un répertoire de données s'il n'existe pas\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Liste des fichiers avec les URL GitHub correspondantes\n",
        "files_to_upload = [\n",
        "    # Revenus trimestriels de NVIDIA 24/25\n",
        "    (\"A_Rev_by_Mkt_Qtrly_Trend_Q425.pdf\", \"https://raw.githubusercontent.com/ContextualAI/examples/refs/heads/main/08-ai-workshop/data/A_Rev_by_Mkt_Qtrly_Trend_Q425.pdf\"),\n",
        "    # Revenus trimestriels de NVIDIA 22/23\n",
        "    (\"B_Q423-Qtrly-Revenue-by-Market-slide.pdf\", \"https://raw.githubusercontent.com/ContextualAI/examples/refs/heads/main/08-ai-workshop/data/B_Q423-Qtrly-Revenue-by-Market-slide.pdf\"),\n",
        "    # Rapport de corrélations fallacieuses - exemple amusant de graphiques et d'analyse statistique\n",
        "    (\"C_Neptune.pdf\", \"https://raw.githubusercontent.com/ContextualAI/examples/refs/heads/main/08-ai-workshop/data/C_Neptune.pdf\"),\n",
        "    # Un autre rapport de corrélations fallacieuses - exemple amusant de graphiques et d'analyse statistique\n",
        "    (\"D_Unilever.pdf\", \"https://raw.githubusercontent.com/ContextualAI/examples/refs/heads/main/08-ai-workshop/data/D_Unilever.pdf\")\n",
        "]"
      ],
      "metadata": {
        "id": "x3mGx-NJ8S0D"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Télecharger les documents et les ajouter à la base de connaissance sur Context Ai ( Context Ai sura créer les chunks =) embeddings avant de les stocker ) dans la base de donnée**"
      ],
      "metadata": {
        "id": "_RbFYwDGEr-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Télécharger et ingérer tous les fichiers\n",
        "document_ids = []\n",
        "for filename, url in files_to_upload:\n",
        "    file_path = f'data/{filename}'\n",
        "\n",
        "    # Télécharger le fichier s'il n'existe pas\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Fetching {file_path}\")\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Lève une exception pour les mauvais codes de statut\n",
        "            with open(file_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors du téléchargement de {filename}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Télécharger vers le datastore\n",
        "    try:\n",
        "        with open(file_path, 'rb') as f:\n",
        "            ingestion_result = client.datastores.documents.ingest(datastore_id, file=f)\n",
        "            document_id = ingestion_result.id\n",
        "            document_ids.append(document_id)\n",
        "            print(f\"Fichier {filename} téléchargé avec succès vers le datastore {datastore_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors du téléchargement de {filename}: {str(e)}\")\n",
        "\n",
        "print(f\"Fichiers téléchargés avec succès vers le datastore : {len(document_ids)}\")\n",
        "print(f\"IDs des documents : {document_ids}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy_fA064FCjC",
        "outputId": "b9e08a32-db85-4b3b-eba6-dd47b3ddc641"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data/A_Rev_by_Mkt_Qtrly_Trend_Q425.pdf\n",
            "Fichier A_Rev_by_Mkt_Qtrly_Trend_Q425.pdf téléchargé avec succès vers le datastore 60c3ed0f-8499-4b95-b59f-ce97bf4eaa31\n",
            "Fetching data/B_Q423-Qtrly-Revenue-by-Market-slide.pdf\n",
            "Fichier B_Q423-Qtrly-Revenue-by-Market-slide.pdf téléchargé avec succès vers le datastore 60c3ed0f-8499-4b95-b59f-ce97bf4eaa31\n",
            "Fetching data/C_Neptune.pdf\n",
            "Fichier C_Neptune.pdf téléchargé avec succès vers le datastore 60c3ed0f-8499-4b95-b59f-ce97bf4eaa31\n",
            "Fetching data/D_Unilever.pdf\n",
            "Fichier D_Unilever.pdf téléchargé avec succès vers le datastore 60c3ed0f-8499-4b95-b59f-ce97bf4eaa31\n",
            "Fichiers téléchargés avec succès vers le datastore : 4\n",
            "IDs des documents : ['7a592fdd-e6ea-4a68-bc51-7909eaf8b3dd', '5e253926-e041-4857-bf35-8a94f88cc7a1', 'cdcd35b5-9753-4929-865f-1cd4ecc3f23e', 'deaa3c1b-f6d7-4cac-96aa-97a4f920bb63']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**En navigant sur le tableau de board de Context Ai dans la base de connaissance on voit que nos documents ont été bien ingérés**"
      ],
      "metadata": {
        "id": "Upm9Nvx6GLI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Vérifons ici cela***"
      ],
      "metadata": {
        "id": "i37WWbwrG9RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = client.datastores.documents.metadata(datastore_id = datastore_id, document_id = document_ids[0])\n",
        "print(\"Document metadata:\", metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB_Z_SilGacS",
        "outputId": "2d0e87c7-9f33-4c49-b1b6-df70490f10f4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document metadata: DocumentMetadata(id='7a592fdd-e6ea-4a68-bc51-7909eaf8b3dd', created_at='2025-09-04T09:38:03.612748', name='A_Rev_by_Mkt_Qtrly_Trend_Q425.pdf', status='completed', custom_metadata={}, custom_metadata_config={}, has_access=True, ingestion_config={'parsing': {'figure_captioning_prompt': None, 'figure_caption_mode': 'default', 'enable_split_tables': True, 'max_split_table_cells': 100, 'ocr_level': 'auto', 'use_hyperlink_extraction': False, 'enable_vlm_hierarchy_inference': True, 'layout_model': 'dit', 'vlm_captioning_model': 'gemini-2.0-flash-001', 'vlm_hierarchy_model': 'gemini-2.0-flash-001', 'vlm_doc_name_model': 'gemini-2.0-flash-001', 'vlm_markdown_reviser_model': None}, 'chunking': {'chunking_mode': 'hierarchy_depth', 'max_chunk_length_tokens': 768, 'min_chunk_length_tokens': 384, 'enable_hierarchy_based_contextualization': True, 'enable_contextualization': None, 'enable_section_based_contextualization': None}, 'html_config': {'max_recursive_depth': 5, 'markdown_links_mode': 'EXTERNAL', 'precise_image_attribution': True, 'enable_section_extraction': True, 'enable_table_links_addition': True, 'max_chunk_length_tokens': 768, 'enable_v2_extraction_pipeline': True}, 'ingestion_types': None, 'enable_v2_extraction_pipeline': True, 'extraction': None}, updated_at=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Création de l'Agent LLM\n",
        "\n",
        "*   Permet de prendre le contexte de la réponse prise par le retriver et la demande de l'utilisateur pour bien etre précis dans la réponse finale\n",
        "\n",
        "\n",
        "\n",
        "*   On a le choix netre un grand nombre de LLM (Prenium, Frenuim partiel, Local) :\n",
        "*   ChatGpt ( Prenium Très rapide, populaire )\n",
        "\n",
        "\n",
        "*   Gemini ( Prenium, Performence reconnue , rapide)\n",
        "*   Grok Ai ( Gratuit à certains niveau, performant )\n",
        "\n",
        "\n",
        "*   DeepSeek\n",
        "*   LLAMA\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sk6swZReIQtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = '''\n",
        "You are a helpful AI assistant created by Contextual AI to answer questions about relevant documentation provided to you. Your responses should be precise, accurate, and sourced exclusively from the provided information. Please follow these guidelines:\n",
        "* Only use information from the provided documentation. Avoid opinions, speculation, or assumptions.\n",
        "* Use the exact terminology and descriptions found in the provided content.\n",
        "* Keep answers concise and relevant to the user's question.\n",
        "* Use acronyms and abbreviations exactly as they appear in the documentation or query.\n",
        "* Apply markdown if your response includes lists, tables, or code.\n",
        "* Directly answer the question, then STOP. Avoid additional explanations unless specifically relevant.\n",
        "* If the information is irrelevant, simply respond that you don't have relevant documentation and do not provide additional comments or suggestions. Ignore anything that cannot be used to directly answer this query.\n",
        "'''\n",
        "agent_name = \"Demo\"\n",
        "\n",
        "# Get list of existing agents\n",
        "# Obtenir la liste des agents existants\n",
        "agents = client.agents.list()\n",
        "\n",
        "# Check if agent already exists\n",
        "# Vérifier si l'agent existe déjà\n",
        "existing_agent = next((agent for agent in agents if agent.name == agent_name), None)\n",
        "\n",
        "if existing_agent:\n",
        "    agent_id = existing_agent.id\n",
        "    print(f\"Using existing agent with ID: {agent_id}\")\n",
        "    # Utilisation de l'agent existant avec l'ID : {agent_id}\n",
        "else:\n",
        "    print(\"Creating new agent\")\n",
        "    # Création d'un nouvel agent\n",
        "    app_response = client.agents.create(\n",
        "        name=agent_name,\n",
        "        description=\"Helpful Grounded AI Assistant\",\n",
        "        # Assistant IA utile basé sur les documents\n",
        "        datastore_ids=[datastore_id],\n",
        "        agent_configs={\n",
        "        \"global_config\": {\n",
        "            \"enable_multi_turn\": False # Turning this off for deterministic responses for this demo\n",
        "            # Désactiver ceci pour des réponses déterministes pour cette démo\n",
        "        }\n",
        "        },\n",
        "        suggested_queries=[\n",
        "            \"What was NVIDIA's annual revenue by fiscal year 2022 to 2025?\",\n",
        "            \"When did NVIDIA's data center revenue overtake gaming revenue?\",\n",
        "            \"What's the correlation between the distance between Neptune and the Sun and Burglary rates in the US?\",\n",
        "            \"What's the correlation between Global revenue generated by Unilever Group and Google searches for 'lost my wallet'?\",\n",
        "            \"Does this imply that Unilever Group's revenue is derived from lost wallets?\",\n",
        "            \"What's the correlation between the distance between Neptune and the Sun and Global revenue generated by Unilever Group?\"\n",
        "        ]\n",
        "    )\n",
        "    agent_id = app_response.id\n",
        "    print(f\"Agent ID created: {agent_id}\")\n",
        "    # ID de l'agent créé : {agent_id}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp3bA4fRKomy",
        "outputId": "973d2155-ab9d-4587-ee38-e9323e26c115"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new agent\n",
            "Agent ID created: 44e42ece-0963-4c5f-9da3-7649d0ef3969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testons l'agent en lui posant une question**"
      ],
      "metadata": {
        "id": "lVmtAQhGMVmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = client.agents.query.create(\n",
        "    agent_id=agent_id,\n",
        "    messages=[{\n",
        "        \"content\": \"What was NVIDIA's Data Center revenue in Q4 FY25??\",\n",
        "        \"role\": \"user\"\n",
        "    }]\n",
        ")\n",
        "print(query_result.message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhdVAtGRMaZR",
        "outputId": "388d42a0-cf90-40d3-c6da-a6aa0698312c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the provided NVIDIA quarterly revenue documentation, I can directly answer your question about Data Center revenue in Q4 FY25:\n",
            "\n",
            "For Q4 FY25, NVIDIA's Data Center revenue was $35,580 million.[1]()()\n",
            "\n",
            "For context, this figure represents the highest quarterly Data Center revenue shown in the provided dataset.\n",
            "\n",
            "It marks an increase from $30,771 million in Q3 FY25 and $18,404 million in Q4 FY24.[1]()()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Super !! Notre agent est bien opérationnel et répond de manière fluide au questions.**"
      ],
      "metadata": {
        "id": "Zeom3hA3Mf5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**On passe à la dernière étape qui consite à tester avec des métrics bien précis pour s'assurer de la fiabilité de notre système RAG avant la mise en production du système**"
      ],
      "metadata": {
        "id": "Xv72QdGeNxOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   *Accuracy (Exatitude des réponses de l'agent), oui l'agent répond mais est ce avec des réponses exactes ?* , posez une question par exemple : Quel était le CA de NVIDAI en 2023 (Ici on s'attend à une réponse exacte)\n",
        "\n",
        "*   \n",
        "\n",
        "*   Causation (Causabilité), oui c'est important, supposons que dans une réponse l'agent mentionne la chutte du CA de Nvidia était du au terrosrisme dans le sahel, la c'est vrai que Nvidia à connue une chutte de son CA mais la cause est loin d'etre nle terrorisme au sahel\n",
        "\n",
        "*   Synthesis (Synthèse) : Ici il sagit de mesurer la capacité de l'agent à faire sortir une synthèse clair, par exemple : Quelle est la moyenne du CA de Nvidia de 2022 à 2025 ?, la belle réponse serait +47.3% en moyenne annuelle et non un nombre fixe\n",
        "\n",
        "\n",
        "*   Limitations (Limites / Transparence) : Ce métric est très important car permet de voir à quel point l'agent allucine ou non, un agent normal devra savoir dire qu'il ne connais si réellement il ne connais pas au lieu de vouloir inventer ou de prendre un context non cohérent pour dévelloper, exemple : Que envisage de faire NVIDIA dans les 10 prochaines années ?, ici l'agent devra dire gentillement qu'il n'a pas de réponse au lieu de se mettre à la place de NVIDIA pour donner des réponses ni tete, ni queue\n",
        "\n",
        "\n",
        "*   Evidence (Preuves / Citations) : Ici on teste pour voir l'agent fournit vraiment des sources au questions qu'on lui pose, pas juste entrain d'affirmer sans les sources.\n",
        "\n",
        "\n",
        "\n",
        "*   Relevance (Pertinence) : Ici la pertinence est crutial car on a bien sur besoin que l'agent soit bien précis, pas la peine de fournir des réponses trop longues sans dire de bon, une réponse raisonnable et precis.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gTqDKKP1OF3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mettons cela en pratique pour voir**"
      ],
      "metadata": {
        "id": "8HjvIMb8RSuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***`LMUnit est l'outils ou le framework utimine pour mener cette mesure des métrics de notre Système RAG`***"
      ],
      "metadata": {
        "id": "wDVNAkA5RuTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Préparons les différentes questions pour le fameux test (6 question, une question pour chaque métric)\n",
        "unit_tests = [\n",
        "      \"Does the response accurately extract specific numerical data from the documents?\",\n",
        "      \"Does the agent properly distinguish between correlation and causation?\",\n",
        "      \"Are multi-document comparisons performed correctly with accurate calculations?\",\n",
        "      \"Are potential limitations or uncertainties in the data clearly acknowledged?\",\n",
        "      \"Are quantitative claims properly supported with specific evidence from the source documents?\",\n",
        "      \"Does the response avoid unnecessary information?\"\n",
        "]"
      ],
      "metadata": {
        "id": "hHaNbrkmMm1C"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testons avec LMUNIT\n",
        "response = client.lmunit.create(\n",
        "                    query=\"What was NVIDIA's Data Center revenue in Q4 FY25?\",\n",
        "                   response = \"\"\"NVIDIA's Data Center revenue for Q4 FY25 was $35,580 million.[1]()\n",
        "\n",
        "                                This represents a significant increase from the previous quarter (Q3 FY25) when Data Center revenue was $30,771 million.[1]()\n",
        "\n",
        "                                The full quarterly trend for Data Center revenue in FY25 was:\n",
        "                                - Q4 FY25: $35,580 million\n",
        "                                - Q3 FY25: $30,771 million\n",
        "                                - Q2 FY25: $26,272 million\n",
        "                                - Q1 FY25: $22,563 million.[1]()\n",
        "                              \"\"\",\n",
        "                    unit_test=\"Does the response avoid unnecessary information?\"\n",
        "                )\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdZlqk5oSN9H",
        "outputId": "0a521a6f-841f-4d5d-a230-700a556e9ea0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LMUnitCreateResponse(score=2.309)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ❌ Mauvaise pratique : tu donnes une réponse trop longue comme input\n",
        "# ✅ Bonne pratique : tu testes la réponse réelle du modèle\n",
        "\n",
        "# Supposons que tu aies un agent\n",
        "actual_response = \"According to the provided NVIDIA quarterly revenue documentation, I can directly answer your question about Data Center revenue in Q4 FY25:\\n\\nFor Q4 FY25, NVIDIA's Data Center revenue was $35,580 million.[1]()()\\n\\nFor context, this figure represents the highest quarterly Data Center revenue shown in the provided dataset.\\n\\nIt marks an increase from $30,771 million in Q3 FY25 and $18,404 million in Q4 FY24.[1]()()\"\n",
        "\n",
        "# Maintenant, tu évalues cette réponse\n",
        "evaluation = client.lmunit.create(\n",
        "    query=\"What was NVIDIA's Data Center revenue in Q4 FY25?\",\n",
        "    response=actual_response,\n",
        "    unit_test=\"Does the response avoid unnecessary information?\"\n",
        ")\n",
        "\n",
        "print(evaluation.score)  # Afficher le score au lieu de 'passed'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37cQSGiMTAOX",
        "outputId": "4d5a8c10-4fa2-447d-d95d-c04b5773e232"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.104\n"
          ]
        }
      ]
    }
  ]
}